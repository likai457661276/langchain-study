"""
å†…å­˜ç®¡ç†ç¤ºä¾‹ - LangChain 1.0 å†…å­˜åŠŸèƒ½

æœ¬ç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•åœ¨LangChain 1.0ä¸­ä½¿ç”¨å†…å­˜åŠŸèƒ½ã€‚
å®ƒå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨LangGraphçš„å†…å­˜å­˜å‚¨æ¥å­˜å‚¨ã€æ£€ç´¢å’Œæœç´¢å†…å­˜ã€‚
"""

import os
from typing import List, Dict, Any
import json
from datetime import datetime

from dotenv import load_dotenv
from langchain.chat_models import init_chat_model
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain.embeddings import init_embeddings
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langgraph.store.memory import InMemoryStore
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.prompt import Prompt

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ–richæ§åˆ¶å°ç”¨äºç¾åŒ–è¾“å‡º
console = Console()


def setup_memory_store():
    """
    è®¾ç½®ä¸€ä¸ªå†…å­˜å­˜å‚¨ç”¨äºæ¼”ç¤ºã€‚
    åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæ‚¨å°†ä½¿ç”¨æŒä¹…åŒ–å­˜å‚¨ã€‚
    """
    # åˆå§‹åŒ–åµŒå…¥
    embeddings = OpenAIEmbeddings(
        model="BAAI/bge-large-zh-v1.5",
        base_url="https://api.siliconflow.cn/v1",
        api_key=os.getenv("SILICONFLOW_API_KEY")
    )
    
    # åˆ›å»ºå¸¦æœ‰åµŒå…¥çš„å†…å­˜å­˜å‚¨
    # æ³¨æ„ï¼šåœ¨å®é™…åº”ç”¨ä¸­ï¼Œæ‚¨å°†ä½¿ç”¨é€‚å½“çš„åµŒå…¥å‡½æ•°
    # å¯¹äºæ­¤æ¼”ç¤ºï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç®€å•çš„æ¨¡æ‹ŸåµŒå…¥å‡½æ•°
    def embed(texts: List[str]) -> List[List[float]]:
        # æ¨¡æ‹ŸåµŒå…¥å‡½æ•° - åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨çœŸå®åµŒå…¥
        return [[hash(text) % 1000 / 1000.0 for _ in range(10)] for text in texts]
    
    store = InMemoryStore(index={"embed": embed, "dims": 10})
    return store


def basic_memory_operations():
    """
    æ¼”ç¤ºåŸºæœ¬å†…å­˜æ“ä½œï¼šputã€getã€searchã€‚
    """
    console.print(Panel.fit("ğŸ’¾ åŸºæœ¬å†…å­˜æ“ä½œ", style="bold blue"))
    
    # è®¾ç½®å†…å­˜å­˜å‚¨
    store = setup_memory_store()
    console.print("[green]âœ“ å†…å­˜å­˜å‚¨å·²åˆå§‹åŒ–[/green]")
    
    # å®šä¹‰ç”¨æˆ·å†…å­˜çš„å‘½åç©ºé—´
    user_id = "demo_user"
    namespace = (user_id, "memories")
    
    # å­˜å‚¨ä¸€äº›å†…å­˜
    memories = [
        {
            "key": "preference",
            "value": {"preference": "ç”¨æˆ·æ›´å–œæ¬¢ç®€æ´çš„ç­”æ¡ˆå’ŒæŠ€æœ¯ç»†èŠ‚ã€‚"}
        },
        {
            "key": "project",
            "value": {"project": "ç”¨æˆ·æ­£åœ¨åšä¸€ä¸ªLangChainå­¦ä¹ é¡¹ç›®ã€‚"}
        },
        {
            "key": "expertise",
            "value": {"expertise": "ç”¨æˆ·å…·æœ‰ä¸­çº§PythonçŸ¥è¯†ï¼Œå¯¹LangChainè¿˜ä¸ç†Ÿæ‚‰ã€‚"}
        }
    ]
    
    console.print("\n[bold]å­˜å‚¨å†…å­˜:[/bold]")
    for memory in memories:
        store.put(namespace, memory["key"], memory["value"])
        console.print(f"  âœ“ å·²å­˜å‚¨ {memory['key']}: {memory['value']}")
    
    # æ£€ç´¢ç‰¹å®šå†…å­˜
    console.print("\n[bold]æ£€ç´¢ç‰¹å®šå†…å­˜:[/bold]")
    retrieved = store.get(namespace, "preference")
    if retrieved:
        console.print(f"  æ£€ç´¢åˆ°çš„åå¥½: {retrieved.value}")
    
    # æœç´¢å†…å­˜
    console.print("\n[bold]æœç´¢å†…å­˜:[/bold]")
    search_results = store.search(namespace, query="ç”¨æˆ·çŸ¥è¯†")
    console.print(f"  æ‰¾åˆ° {len(search_results)} ä¸ªåŒ¹é…'ç”¨æˆ·çŸ¥è¯†'çš„å†…å­˜:")
    for result in search_results:
        console.print(f"    - {result.key}: {result.value}")
    
    # åˆ—å‡ºå‘½åç©ºé—´ä¸­çš„æ‰€æœ‰å†…å­˜
    console.print("\n[bold]å‘½åç©ºé—´ä¸­çš„æ‰€æœ‰å†…å­˜:[/bold]")
    all_items = store.search(namespace)
    for item in all_items:
        console.print(f"    - {item.key}: {item.value}")


def conversation_memory_demo():
    """
    æ¼”ç¤ºå¦‚ä½•åœ¨å¯¹è¯ä¸Šä¸‹æ–‡ä¸­ä½¿ç”¨å†…å­˜ã€‚
    """
    console.print(Panel.fit("ğŸ’¬ å¯¹è¯å†…å­˜æ¼”ç¤º", style="bold blue"))
    
    # åˆå§‹åŒ–æ¨¡å‹å’Œå†…å­˜å­˜å‚¨
    model = init_chat_model("gpt-4o-mini", model_provider="openai")
    store = setup_memory_store()
    
    # å®šä¹‰å¯¹è¯å†…å­˜çš„å‘½åç©ºé—´
    user_id = "demo_user"
    namespace = (user_id, "conversation")
    
    # å­˜å‚¨å¯¹è¯ä¸Šä¸‹æ–‡
    conversation_context = {
        "topic": "LangChainå­¦ä¹ ",
        "user_goals": "äº†è§£å¦‚ä½•ä½¿ç”¨LangChain 1.0æ„å»ºAIåº”ç”¨ç¨‹åº",
        "previous_discussions": [
            "ç”¨æˆ·è¯¢é—®äº†åŸºæœ¬èŠå¤©è®¾ç½®",
            "ç”¨æˆ·è¯¢é—®äº†ä»£ç†å’Œå·¥å…·",
            "ç”¨æˆ·æƒ³äº†è§£å†…å­˜ç®¡ç†"
        ]
    }
    
    store.put(namespace, "context", conversation_context)
    
    console.print("[green]âœ“ å¯¹è¯ä¸Šä¸‹æ–‡å·²å­˜å‚¨[/green]")
    
    # æ¨¡æ‹Ÿå¸¦æœ‰å†…å­˜çš„å¯¹è¯
    console.print("\n[bold]æ¨¡æ‹Ÿå¸¦æœ‰å†…å­˜çš„å¯¹è¯:[/bold]\n")
    
    # ç¬¬ä¸€æ¡æ¶ˆæ¯
    user_message = "ä½ èƒ½å¸®æˆ‘ç†è§£LangChainçš„å†…å­˜åŠŸèƒ½å—ï¼Ÿ"
    
    # åœ¨å“åº”å‰æ£€ç´¢ç›¸å…³å†…å­˜
    memories = store.search(namespace, query="å†…å­˜åŠŸèƒ½")
    
    # æ ¼å¼åŒ–å†…å­˜ç”¨äºä¸Šä¸‹æ–‡
    memory_context = "\n".join([f"- {item.key}: {item.value}" for item in memories])
    
    # åˆ›å»ºå¸¦æœ‰å†…å­˜ä¸Šä¸‹æ–‡çš„æç¤º
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªå­¦ä¹ LangChainçš„å¾—åŠ›åŠ©æ‰‹ã€‚
    
    ä¹‹å‰çš„å¯¹è¯ä¸Šä¸‹æ–‡:
    {memory_context}
    
    ä½¿ç”¨æ­¤ä¸Šä¸‹æ–‡æä¾›ä¸ªæ€§åŒ–å“åº”ã€‚
    """
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_message)
    ]
    
    # è·å–æ¨¡å‹å“åº”
    response = model.invoke(messages)
    
    console.print(f"[bold blue]ç”¨æˆ·:[/bold blue] {user_message}")
    console.print(f"[bold green]åŠ©æ‰‹:[/bold green] {response.content}")
    
    # å°†æ­¤äº¤äº’å­˜å‚¨åœ¨å†…å­˜ä¸­
    interaction = {
        "timestamp": datetime.now().isoformat(),
        "user_message": user_message,
        "assistant_response": response.content
    }
    
    store.put(namespace, f"interaction_{datetime.now().strftime('%Y%m%d_%H%M%S')}", interaction)
    console.print("[green]âœ“ äº¤äº’å·²å­˜å‚¨åœ¨å†…å­˜ä¸­[/green]")


def vector_memory_demo():
    """
    æ¼”ç¤ºåŸºäºå‘é‡çš„å†…å­˜å­˜å‚¨å’Œæ£€ç´¢ã€‚
    """
    console.print(Panel.fit("ğŸ” å‘é‡å†…å­˜æ¼”ç¤º", style="bold blue"))
    
    # åˆå§‹åŒ–åµŒå…¥
    embeddings = OpenAIEmbeddings(
        model="BAAI/bge-large-zh-v1.5",
        base_url="https://api.siliconflow.cn/v1",
        api_key=os.getenv("SILICONFLOW_API_KEY")
    )
    
    # ä½¿ç”¨Chromaåˆ›å»ºç®€å•çš„å‘é‡å­˜å‚¨
    vector_store = Chroma(
        collection_name="langchain_memories",
        embedding_function=embeddings,
        persist_directory="./chroma_langchain_db"
    )
    
    console.print("[green]âœ“ å‘é‡å­˜å‚¨å·²åˆå§‹åŒ–[/green]")
    
    # å‘å‘é‡å­˜å‚¨æ·»åŠ ä¸€äº›æ–‡æ¡£
    documents = [
        "LangChainæ˜¯ä¸€ä¸ªç”¨äºæ„å»ºç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„åº”ç”¨ç¨‹åºçš„æ¡†æ¶ã€‚",
        "LangChainä¸­çš„ä»£ç†å¯ä»¥ä½¿ç”¨å·¥å…·æ‰§è¡Œæ“ä½œå’Œæ”¶é›†ä¿¡æ¯ã€‚",
        "LangChainä¸­çš„å†…å­˜å…è®¸åº”ç”¨ç¨‹åºè®°ä½ä¹‹å‰çš„äº¤äº’ã€‚",
        "LangChain 1.0å¼•å…¥äº†create_agentå‡½æ•°ï¼Œä½¿ä»£ç†åˆ›å»ºæ›´å®¹æ˜“ã€‚",
        "LangGraphæä¾›äº†ä¸€ä¸ªç”¨äºæ„å»ºä»£ç†çš„ä½çº§ç¼–æ’æ¡†æ¶ã€‚"
    ]
    
    # æ·»åŠ å¸¦æœ‰IDçš„æ–‡æ¡£
    ids = [f"doc_{i}" for i in range(len(documents))]
    vector_store.add_texts(texts=documents, ids=ids)
    
    console.print(f"[green]âœ“ å·²å‘å‘é‡å­˜å‚¨æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£[/green]")
    
    # æœç´¢ç›¸ä¼¼æ–‡æ¡£
    query = "å¦‚ä½•åœ¨LangChainä¸­åˆ›å»ºä»£ç†ï¼Ÿ"
    console.print(f"\n[bold]æœç´¢ä¸ä»¥ä¸‹å†…å®¹ç›¸ä¼¼çš„æ–‡æ¡£:[/bold] {query}")
    
    results = vector_store.similarity_search_with_score(query, k=3)
    
    console.print(f"\n[bold]æ‰¾åˆ° {len(results)} ä¸ªç›¸ä¼¼æ–‡æ¡£:[/bold]\n")
    for i, (doc, score) in enumerate(results):
        console.print(f"[bold]ç»“æœ {i+1}[/bold] (å¾—åˆ†: {score:.4f}):")
        console.print(f"  {doc.page_content}\n")


def long_term_memory_demo():
    """
    æ¼”ç¤ºä½¿ç”¨ç”¨æˆ·æ¡£æ¡ˆçš„é•¿æœŸå†…å­˜ç®¡ç†ã€‚
    """
    console.print(Panel.fit("ğŸ§  é•¿æœŸå†…å­˜æ¼”ç¤º", style="bold blue"))
    
    # åˆå§‹åŒ–æ¨¡å‹å’Œå†…å­˜å­˜å‚¨
    model = init_chat_model("gpt-4o-mini", model_provider="openai")
    store = setup_memory_store()
    
    # åˆ›å»ºç”¨æˆ·æ¡£æ¡ˆ
    user_id = "demo_user"
    profile_namespace = (user_id, "profile")
    memories_namespace = (user_id, "memories")
    
    # å­˜å‚¨ç”¨æˆ·æ¡£æ¡ˆ
    profile = {
        "name": "æ¼”ç¤ºç”¨æˆ·",
        "preferences": {
            "response_style": "ç®€æ´",
            "technical_level": "ä¸­çº§",
            "interests": ["AI", "Python", "LangChain"]
        },
        "learning_goals": [
            "ç†è§£LangChainåŸºç¡€çŸ¥è¯†",
            "æ„å»ºAIåº”ç”¨ç¨‹åº",
            "äº†è§£ä»£ç†å’Œå·¥å…·"
        ],
        "last_interaction": datetime.now().isoformat()
    }
    
    store.put(profile_namespace, "user_profile", profile)
    console.print("[green]âœ“ ç”¨æˆ·æ¡£æ¡ˆå·²å­˜å‚¨[/green]")
    
    # å­˜å‚¨ä¸€äº›ç‰¹å®šçš„å†…å­˜
    memories = [
        {"key": "question_1", "value": {"question": "ä»€ä¹ˆæ˜¯LangChainï¼Ÿ", "answer": "ä¸€ä¸ªç”¨äºLLMåº”ç”¨ç¨‹åºçš„æ¡†æ¶"}},
        {"key": "question_2", "value": {"question": "å¦‚ä½•åˆ›å»ºä»£ç†ï¼Ÿ", "answer": "ä½¿ç”¨create_agentå‡½æ•°"}},
        {"key": "question_3", "value": {"question": "æœ‰å“ªäº›å·¥å…·å¯ç”¨ï¼Ÿ", "answer": "å„ç§ç”¨äºç½‘ç»œæœç´¢ã€è®¡ç®—ç­‰çš„å·¥å…·"}}
    ]
    
    for memory in memories:
        store.put(memories_namespace, memory["key"], memory["value"])
    
    console.print(f"[green]âœ“ å·²å­˜å‚¨ {len(memories)} ä¸ªé—®ç­”å†…å­˜[/green]")
    
    # æ£€ç´¢ç”¨æˆ·æ¡£æ¡ˆ
    user_profile = store.get(profile_namespace, "user_profile")
    console.print("\n[bold]ç”¨æˆ·æ¡£æ¡ˆ:[/bold]")
    console.print(f"  å§“å: {user_profile.value['name']}")
    console.print(f"  å“åº”é£æ ¼: {user_profile.value['preferences']['response_style']}")
    console.print(f"  æŠ€æœ¯æ°´å¹³: {user_profile.value['preferences']['technical_level']}")
    console.print(f"  å…´è¶£: {', '.join(user_profile.value['preferences']['interests'])}")
    
    # æ ¹æ®æŸ¥è¯¢æœç´¢ç›¸å…³å†…å­˜
    query = "ä»£ç†åˆ›å»º"
    console.print(f"\n[bold]æœç´¢å†…å­˜:[/bold] {query}")
    
    relevant_memories = store.search(memories_namespace, query=query)
    console.print(f"[bold]æ‰¾åˆ° {len(relevant_memories)} ä¸ªç›¸å…³å†…å­˜:[/bold]")
    
    for memory in relevant_memories:
        console.print(f"  - {memory.value['question']}: {memory.value['answer']}")
    
    # æ¨¡æ‹ŸåŸºäºæ¡£æ¡ˆå’Œå†…å­˜çš„ä¸ªæ€§åŒ–å“åº”
    console.print("\n[bold]æ¨¡æ‹Ÿä¸ªæ€§åŒ–å“åº”:[/bold]\n")
    
    # è·å–ç›¸å…³å†…å­˜
    memories_context = "\n".join([
        f"- {mem.value['question']}: {mem.value['answer']}" 
        for mem in relevant_memories
    ])
    
    # åˆ›å»ºä¸ªæ€§åŒ–æç¤º
    system_prompt = f"""ä½ æ˜¯ {user_profile.value['name']} çš„å¾—åŠ›åŠ©æ‰‹ã€‚
    
    ç”¨æˆ·æ¡£æ¡ˆ:
    - å“åº”é£æ ¼: {user_profile.value['preferences']['response_style']}
    - æŠ€æœ¯æ°´å¹³: {user_profile.value['preferences']['technical_level']}
    - å…´è¶£: {', '.join(user_profile.value['preferences']['interests'])}
    
    ä¹‹å‰çš„é—®ç­”:
    {memories_context}
    
    æä¾›ç¬¦åˆç”¨æˆ·åå¥½å¹¶åŸºäºå…¶ä¹‹å‰çŸ¥è¯†çš„å“åº”ã€‚
    """
    
    user_question = "ä½ èƒ½è¯¦ç»†è§£é‡Šä¸€ä¸‹LangChainä¸­çš„ä»£ç†åˆ›å»ºå—ï¼Ÿ"
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_question)
    ]
    
    response = model.invoke(messages)
    
    console.print(f"[bold blue]ç”¨æˆ·:[/bold blue] {user_question}")
    console.print(f"[bold green]åŠ©æ‰‹:[/bold green] {response.content}")
    
    # æ›´æ–°æœ€åäº¤äº’æ—¶é—´
    profile["last_interaction"] = datetime.now().isoformat()
    store.put(profile_namespace, "user_profile", profile)
    console.print("[green]âœ“ å·²æ›´æ–°æœ€åäº¤äº’æ—¶é—´[/green]")


if __name__ == "__main__":
    console.print(Panel.fit("LangChain 1.0 å†…å­˜ç®¡ç†ç¤ºä¾‹", style="bold blue"))
    
    choice = console.input(
        "\n[bold]é€‰æ‹©è¦è¿è¡Œçš„ç¤ºä¾‹:[/bold]\n"
        "1. åŸºæœ¬å†…å­˜æ“ä½œ\n"
        "2. å¯¹è¯å†…å­˜æ¼”ç¤º\n"
        "3. å‘é‡å†…å­˜æ¼”ç¤º\n"
        "4. é•¿æœŸå†…å­˜æ¼”ç¤º\n"
        "[bold]è¾“å…¥æ‚¨çš„é€‰æ‹© (1-4):[/bold] "
    )
    
    if choice == "1":
        basic_memory_operations()
    elif choice == "2":
        conversation_memory_demo()
    elif choice == "3":
        vector_memory_demo()
    elif choice == "4":
        long_term_memory_demo()
    else:
        console.print("[red]æ— æ•ˆé€‰æ‹©ã€‚è¯·å†æ¬¡è¿è¡Œè„šæœ¬ã€‚[/red]")
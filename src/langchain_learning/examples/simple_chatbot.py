"""
ä¸­æ–‡èŠå¤©åŠ©æ‰‹ç¤ºä¾‹ - åŸºäºç¡…åŸºæµåŠ¨çš„ LangChain 1.0 åº”ç”¨

æ­¤ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨ LangChain 1.0 å’Œç¡…åŸºæµåŠ¨å¹³å°åˆ›å»ºä¸€ä¸ªä¸­æ–‡èŠå¤©åŠ©æ‰‹ã€‚
å®ƒæ¼”ç¤ºäº†åŸºæœ¬è®¾ç½®ã€æ¶ˆæ¯å¤„ç†å’Œä¸­æ–‡å¯¹è¯åŠŸèƒ½ã€‚
"""

import os
import sys
from pathlib import Path
from typing import List

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from rich.console import Console
from rich.panel import Panel
from rich.text import Text

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root / "src"))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ– Rich æ§åˆ¶å°ä»¥ç¾åŒ–è¾“å‡º
console = Console()


def initialize_siliconflow_model(model: str = "Qwen/Qwen3-8B"):
    """
    åˆå§‹åŒ–åŸºäºç¡…åŸºæµåŠ¨çš„èŠå¤©æ¨¡å‹ã€‚
    
    Args:
        model: è¦ä½¿ç”¨çš„ç‰¹å®šæ¨¡å‹åç§°
    
    Returns:
        åˆå§‹åŒ–åçš„èŠå¤©æ¨¡å‹
    """
    api_key = os.getenv("SILICONFLOW_API_KEY")
    
    if not api_key:
        raise ValueError("æœªæ‰¾åˆ° SILICONFLOW_API_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")
    
    # ä½¿ç”¨ ChatOpenAI ç±»è¿æ¥ç¡…åŸºæµåŠ¨çš„ API
    # ç¡…åŸºæµåŠ¨å…¼å®¹ OpenAI API æ ¼å¼
    chat_model = ChatOpenAI(
        model=model,
        openai_api_base="https://api.siliconflow.cn/v1",
        openai_api_key=api_key,
        temperature=0.7,
        max_tokens=1024,
        streaming=True,  # å¯ç”¨æµå¼å“åº”
    )
    
    return chat_model


def list_available_models():
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹é€‰é¡¹ã€‚
    
    Returns:
        åŒ…å«æ¨¡å‹IDå’Œæ˜¾ç¤ºåç§°çš„å­—å…¸åˆ—è¡¨
    """
    return [
        {"id": "Qwen/Qwen3-8B", "name": "é€šä¹‰åƒé—® Qwen3-8B (é»˜è®¤)"},
        {"id": "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B", "name": "DeepSeek-R1-0528-Qwen3-8B"},
        {"id": "THUDM/GLM-Z1-9B-0414", "name": "æ¸…å GLM-Z1-9B-0414"},
        {"id": "THUDM/glm-4-9b-chat", "name": "æ¸…å GLM-4-9B-Chat"}
    ]


def select_model():
    """
    æä¾›æ¨¡å‹é€‰æ‹©ç•Œé¢ã€‚
    
    Returns:
        ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹ID
    """
    models = list_available_models()
    
    console.print("\n[bold]è¯·é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹:[/bold]\n")
    
    for i, model in enumerate(models, 1):
        console.print(f"{i}. {model['name']}")
    
    while True:
        choice = console.input(f"\n[bold]è¾“å…¥æ‚¨çš„é€‰æ‹© (1-{len(models)})ï¼Œæˆ–æŒ‰å›è½¦ä½¿ç”¨é»˜è®¤æ¨¡å‹:[/bold] ")
        
        if not choice:
            # ä½¿ç”¨é»˜è®¤æ¨¡å‹
            console.print(f"[green]å·²é€‰æ‹©é»˜è®¤æ¨¡å‹: {models[0]['name']}[/green]")
            return models[0]["id"]
        
        try:
            choice_index = int(choice) - 1
            if 0 <= choice_index < len(models):
                selected_model = models[choice_index]
                console.print(f"[green]å·²é€‰æ‹©: {selected_model['name']}[/green]")
                return selected_model["id"]
            else:
                console.print(f"[red]æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1 åˆ° {len(models)} ä¹‹é—´çš„æ•°å­—[/red]")
        except ValueError:
            console.print("[red]è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—[/red]")


def chinese_chat():
    """
    è¿è¡Œä¸€ä¸ªä¸­æ–‡èŠå¤©ä¼šè¯ã€‚
    """
    console.print(Panel.fit("ğŸ¤– ä¸­æ–‡èŠå¤©åŠ©æ‰‹", style="bold blue"))
    
    # é€‰æ‹©æ¨¡å‹
    selected_model = select_model()
    
    # åˆå§‹åŒ–æ¨¡å‹
    try:
        model = initialize_siliconflow_model(selected_model)
        console.print(f"[green]âœ“ å·²è¿æ¥åˆ°æ¨¡å‹: {selected_model}[/green]")
    except Exception as e:
        console.print(f"[red]âœ— æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}[/red]")
        console.print("[red]è¯·ç¡®ä¿æ‚¨å·²åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®äº† SILICONFLOW_API_KEY[/red]")
        return
    
    # å¼€å§‹èŠå¤©ä¼šè¯
    console.print("\n[bold green]èŠå¤©å·²å¼€å§‹ï¼è¾“å…¥ 'é€€å‡º' æˆ– 'quit' ç»“æŸå¯¹è¯ã€‚[bold green]\n")
    
    # åˆå§‹åŒ–æ¶ˆæ¯å†å²
    messages: List = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ä¸­æ–‡åŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ï¼Œä¿æŒç®€æ´å’Œç¤¼è²Œã€‚")
    ]
    
    while True:
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = console.input("[bold blue]ä½ :[/bold blue] ")
        
        if user_input.lower() in ["é€€å‡º", "quit", "exit", "q"]:
            console.print("[bold green]å†è§ï¼[bold green]")
            break
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        messages.append(HumanMessage(content=user_input))
        
        try:
            # æ˜¾ç¤ºåŠ©æ‰‹æ­£åœ¨æ€è€ƒçš„æç¤º
            console.print("[bold green]åŠ©æ‰‹:[/bold green]", end=" ")
            
            # æµå¼è·å–æ¨¡å‹å“åº”
            full_response = ""
            for chunk in model.stream(messages):
                if hasattr(chunk, 'content') and chunk.content:
                    console.print(chunk.content, end="")
                    full_response += chunk.content
            
            # æ·»åŠ å®Œæ•´å“åº”åˆ°å†å²
            messages.append(AIMessage(content=full_response))
            
            # æ·»åŠ æ¢è¡Œç¬¦
            console.print()
        except Exception as e:
            console.print(f"\n[red]é”™è¯¯: {e}[/red]")


def message_types_demo():
    """
    æ¼”ç¤º LangChain ä¸­çš„ä¸åŒæ¶ˆæ¯ç±»å‹ã€‚
    """
    console.print(Panel.fit("ğŸ“ æ¶ˆæ¯ç±»å‹æ¼”ç¤º", style="bold blue"))
    
    # é€‰æ‹©æ¨¡å‹
    selected_model = select_model()
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = initialize_siliconflow_model(selected_model)
    
    # åˆ›å»ºä¸åŒç±»å‹çš„æ¶ˆæ¯
    system_msg = SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªè§£é‡Šæ¦‚å¿µçš„åŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡å›ç­”ã€‚")
    human_msg = HumanMessage(content="LangChain ä¸­æœ‰å“ªäº›ä¸åŒç±»å‹çš„æ¶ˆæ¯ï¼Ÿ")
    ai_msg = AIMessage(content="LangChain æ”¯æŒå¤šç§æ¶ˆæ¯ç±»å‹ï¼ŒåŒ…æ‹¬ SystemMessageã€HumanMessage å’Œ AIMessageã€‚")
    
    # ä½¿ç”¨è¿™äº›æ¶ˆæ¯åˆ›å»ºå¯¹è¯
    messages = [system_msg, human_msg, ai_msg]
    
    # æ·»åŠ å¦ä¸€ä¸ªäººç±»æ¶ˆæ¯ä»¥ç»§ç»­å¯¹è¯
    messages.append(HumanMessage(content="ä½ èƒ½ç»™æˆ‘å±•ç¤ºå¦‚ä½•åœ¨ä»£ç ä¸­ä½¿ç”¨å®ƒä»¬å—ï¼Ÿ"))
    
    # è·å–å“åº”
    response = model.invoke(messages)
    
    # æ˜¾ç¤ºå¯¹è¯
    console.print("\n[bold]å¯¹è¯:[bold]\n")
    
    for msg in messages:
        if isinstance(msg, SystemMessage):
            console.print(f"[bold magenta]ç³»ç»Ÿ:[/bold magenta] {msg.content}")
        elif isinstance(msg, HumanMessage):
            console.print(f"[bold blue]ç”¨æˆ·:[/bold blue] {msg.content}")
        elif isinstance(msg, AIMessage):
            console.print(f"[bold green]AI:[/bold green] {msg.content}")
    
    # æ˜¾ç¤ºæœ€ç»ˆå“åº”
    console.print(f"\n[bold green]AI å“åº”:[/bold green] {response.content}")


def streaming_demo():
    """
    æ¼”ç¤ºæ¨¡å‹çš„æµå¼å“åº”ã€‚
    """
    console.print(Panel.fit("ğŸŒŠ æµå¼å“åº”æ¼”ç¤º", style="bold blue"))
    
    # é€‰æ‹©æ¨¡å‹
    selected_model = select_model()
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = initialize_siliconflow_model(selected_model)
    
    # è·å–ç”¨æˆ·è¾“å…¥
    prompt = console.input("[bold blue]è¾“å…¥ä¸€ä¸ªç”¨äºæµå¼å“åº”çš„æç¤º:[/bold blue] ")
    
    if not prompt:
        prompt = "ç»™æˆ‘è®²ä¸€ä¸ªå…³äºæœºå™¨äººå­¦ä¹ ç»˜ç”»çš„çŸ­æ•…äº‹ã€‚"
    
    console.print("\n[bold green]æµå¼å“åº”:[/bold green]\n")
    
    # æµå¼è·å–å“åº”
    full_response = ""
    for chunk in model.stream([HumanMessage(content=prompt)]):
        if hasattr(chunk, 'content') and chunk.content:
            console.print(chunk.content, end="")
            full_response += chunk.content
    
    console.print("\n\n[bold]å®Œæ•´å“åº”å·²æ¥æ”¶ï¼[bold]")


def show_models():
    """
    æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨ã€‚
    """
    console.print(Panel.fit("ğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨", style="bold blue"))
    
    models = list_available_models()
    
    console.print("\n[bold]å½“å‰æ”¯æŒçš„æ¨¡å‹:[/bold]\n")
    
    for i, model in enumerate(models, 1):
        console.print(f"{i}. [bold cyan]{model['id']}[/bold cyan]")
        console.print(f"   {model['name']}\n")
    
    console.print("[green]æç¤º: åœ¨é€‰æ‹©ç¤ºä¾‹æ—¶ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ä½¿ç”¨ä»»ä½•è¿™äº›æ¨¡å‹ã€‚[/green]")


if __name__ == "__main__":
    console.print(Panel.fit("LangChain 1.0 ä¸­æ–‡èŠå¤©åŠ©æ‰‹ç¤ºä¾‹", style="bold blue"))
    
    choice = console.input(
        "\n[bold]é€‰æ‹©è¦è¿è¡Œçš„ç¤ºä¾‹:[/bold]\n"
        "1. ä¸­æ–‡èŠå¤©\n"
        "2. æ¶ˆæ¯ç±»å‹æ¼”ç¤º\n"
        "3. æµå¼å“åº”æ¼”ç¤º\n"
        "4. æŸ¥çœ‹å¯ç”¨æ¨¡å‹\n"
        "[bold]è¾“å…¥æ‚¨çš„é€‰æ‹© (1-4):[/bold] "
    )
    
    if choice == "1":
        chinese_chat()
    elif choice == "2":
        message_types_demo()
    elif choice == "3":
        streaming_demo()
    elif choice == "4":
        show_models()
    else:
        console.print("[red]æ— æ•ˆé€‰æ‹©ã€‚è¯·å†æ¬¡è¿è¡Œè„šæœ¬ã€‚[red]")